---
title: "STA 380 Exercise 2"
author: "Shreyas K.S."
geometry: margin=1in
output: word_document
fontsize: 11pt
---

```{r, include=F}
require(ggplot2)
require(gridExtra)
require(RColorBrewer)
my_seed = set.seed(48392)
```

## Introduction
This exercise goes over 3 questions: exploratory data analysis at ABIA, author attribution for Reuters articles, and association rules in music.

## Exploratory Data Analysis: Flights at ABIA
Austin Bergstrom International Airport (ABIA) is the only major domestic airport at Austin, Texas. The data set being explored here contains flights in and out of ABIA in 2008. First, lets start by loading and partitioning the data into incoming and outgoing flights from/to Austin:

```{r}
abia = read.csv("ABIA.csv", header=TRUE)
incoming <- subset(abia, Dest == "AUS")
outgoing <- subset(abia, Origin == "AUS")
```

Since Austin is known for its beautiful weather, I start by looking at how forecasted weather delay relates to actual delay in departure. Both these attributes correspond to the airport of origin, hence they can be compared. I start by cleaning up the data. I drop NA values in Weather Delays for incoming and outgoing flights.


```{r}
in_weather <- subset(incoming, !is.na(incoming[,26]))
in_weather <- subset(in_weather, WeatherDelay>0)
out_weather <- subset(outgoing, !is.na(incoming[,26]))
out_weather <- subset(out_weather, WeatherDelay>0)

```

The following set of plots shows the difference in forecasted delay due to weather and actual delay in departure for incoming and outgoing flights:

```{r, echo=FALSE}
plot1 <- ggplot(in_weather, aes(WeatherDelay, DepDelay )) + geom_point() + 
  geom_abline(a=0, b=1) + ggtitle("Incoming Flights") + guides(col=guide_legend(ncol=2))
plot2 <- ggplot(out_weather, aes(WeatherDelay, DepDelay)) + geom_point() + 
  geom_abline(a=0, b=1) + ggtitle("Outgoing Flights") + guides(col=guide_legend(ncol=2))

grid.arrange(plot1, plot2, nrow=2, ncol=1)
```

A line of slope 1 and origin 0 (Line formula:`y=x`) is included in the plots. Being along the line means forecasted weather delay was exactly equal to actual departure delay. A point below the line represents a flight taking off in less time than its predicted delay due to weather. 

One extremely surprising observation is that for flights going out of Austin, every time there a weather delay is forecasted, the flight is delayed by the time of predicted weather delay or higher. This is helpful information for travelers out of Austin when it comes to planning their trip to the airport.

The differences between incoming and outgoing flights may be because of two reasons. An airport may generally be safer (less security delay), less busy (less overall aircrafts compared to other airports and less late aircraft delay), or have better airport staff (less carrier delay). Let's look closely at the airports with delays. Lets try to analyze this in more detail.

```{r, echo=F}
ggplot(in_weather, aes(WeatherDelay, DepDelay, size = Distance)) + geom_point(aes(colour=UniqueCarrier),shape=24) + geom_abline(a=0, b=1) + ggtitle("Delays in Incoming Flights") + guides(col=guide_legend(ncol=2))
```


The above graph is similar to the visuals we saw earlier, but gives us more information. The color of each point is the carrier. We can't see many clear trends in carriers when it comes to excess delay. However, we can see that more long distance flights are involved when there is excess delay. 

Lets call the difference between expected weather delay and actual departure delay excess delays. Excess delays can be represented by the vertical distance between a point and the line. Lets subset the data further to look into this. There are 612 flights which have been delayed due to weather AND other reasons. The following plot shows the excess delay (in minutes) against origin:

```{r, echo=F}
in_weather$ex_del = in_weather$DepDelay - in_weather$WeatherDelay
out_weather$ex_del = out_weather$DepDelay - out_weather$WeatherDelay
exdel = rbind(in_weather, out_weather)
excess_delay <- subset(exdel, ex_del>0)

ggplot(excess_delay, aes(Origin,ex_del)) + geom_bin2d() + ylab("Excess Delay") + xlab("Origin") + 
  ggtitle("Excess Delay by Origin") + theme(axis.text.x  = element_text(angle=90))
```

We can see that most of the points are towards the lower half of the plot, which means excess delays were generally less than 200 minutes. The lighter shades are seen in Austin (AUS), Dallas Fort Worth (DFW), Chicago O'Hare (ORD), George Bush Intercontinental Houston (IAH), Hartsfield Jackson Atlanta (ATL). These airports had most excess delays. This is not very surprising, since most of these airports are major international airports. Additionally, DFW, ORD, and IAH are hubs for either United or American Airlines, which are the two biggest airlines in the country. Delta uses ATL as a hub. A delay in one of these hub airports may cascade and go on to affect other flights, which is what we might be seeing here.

It is generally difficult to map out the exact reason for a cancellation or delay in airplanes. However, exploratory analysis of the data shows that in Austin, any predicted weather delay results in a delay of longer, and hub airports tend to have a higher frequency of delays.

## Author Attribution 
A Naive Bayes model was run on the data.
```{r}
library(tm)
library(randomForest)
library(e1071)
library(rpart)
library(ggplot2)
library(caret)

readerPlain = function(fname){
  readPlain(elem=list(content=readLines(fname)), id=fname, language='en') }

author_dirs = Sys.glob('ReutersC50/C50train/*')
file_list = NULL
train_labels = NULL
for(author in author_dirs) {
  author_name = substring(author, first=23)
  files_to_add = Sys.glob(paste0(author, '/*.txt'))
  file_list = append(file_list, files_to_add)
  train_labels = append(train_labels, rep(author_name, length(files_to_add)))
}

all_docs = lapply(file_list, readerPlain) 
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))
train_corpus = Corpus(VectorSource(all_docs))
names(train_corpus) = file_list
train_corpus = tm_map(train_corpus, content_transformer(tolower)) 
train_corpus = tm_map(train_corpus, content_transformer(removeNumbers)) 
train_corpus = tm_map(train_corpus, content_transformer(removePunctuation)) 
train_corpus = tm_map(train_corpus, content_transformer(stripWhitespace)) 
train_corpus = tm_map(train_corpus, content_transformer(removeWords), stopwords("SMART"))
DTM_train = DocumentTermMatrix(train_corpus)
DTM_train = removeSparseTerms(DTM_train, 0.975)
DTM_train
author_dirs = Sys.glob('ReutersC50/C50test/*')
file_list = NULL
test_labels = NULL
for(author in author_dirs) {
  author_name = substring(author, first=22)
  files_to_add = Sys.glob(paste0(author, '/*.txt'))
  file_list = append(file_list, files_to_add)
  test_labels = append(test_labels, rep(author_name, length(files_to_add)))
}
all_docs = lapply(file_list, readerPlain) 
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))
test_corpus = Corpus(VectorSource(all_docs))
names(test_corpus) = file_list
test_corpus = tm_map(test_corpus, content_transformer(tolower)) 
test_corpus = tm_map(test_corpus, content_transformer(removeNumbers)) 
test_corpus = tm_map(test_corpus, content_transformer(removePunctuation)) 
test_corpus = tm_map(test_corpus, content_transformer(stripWhitespace)) 
test_corpus = tm_map(test_corpus, content_transformer(removeWords), stopwords("SMART"))
reuters_dict = NULL
reuters_dict = dimnames(DTM_train)[[2]]
DTM_test = DocumentTermMatrix(test_corpus, list(dictionary=reuters_dict))
DTM_test = removeSparseTerms(DTM_test, 0.975)
DTM_train_df = as.data.frame(inspect(DTM_train))
DTM_test_df = as.data.frame(inspect(DTM_test))
model_NB = naiveBayes(x=DTM_train_df, y=as.factor(train_labels), laplace=1)
pred_NB = predict(model_NB, DTM_test_df)

conf_NB = confusionMatrix(table(pred_NB,test_labels))
conf_NB_df = as.data.frame(conf_NB$byClass)
conf_NB_df[order(-conf_NB_df$Sensitivity),1:2]
```

The model evaluation is as follows:
```{r, echo=F}
conf_NB$overall
```
The model accuracy is 0.185. Next, lets look at a random forest model and compare it to the naive bayes model.

```{r, echo=F, include=F}
DTM_test = as.matrix(DTM_test)
DTM_train = as.matrix(DTM_train)
xx <- data.frame(DTM_test[,intersect(colnames(DTM_test), colnames(DTM_train))])
yy <- read.table(textConnection(""), col.names = colnames(DTM_train), colClasses = "integer")
library(plyr)
DTM_test_clean = rbind.fill(xx, yy)
DTM_test_df = as.data.frame(DTM_test_clean)
model_RF = randomForest(x=DTM_train_df, y=as.factor(train_labels), mtry=4, ntree=100)
pred_RF = predict(model_RF, data=DTM_test_clean)
table_RF = as.data.frame(table(pred_RF,test_labels))
conf_RF = confusionMatrix(table(pred_RF,test_labels))
conf_RF_df = as.data.frame(conf_RF$byClass)

conf_RF$overall

```

The random forest model accuracy is 0.65, which is significantly higher than the naive bayes model's accuracy. 

Random forest is a better classifier than Naive Bayes in this context. Lets verify this by looking at a plot of specificity against sensitivity for both models:


```{r, echo=F}
plot3 <- ggplot(conf_NB_df, aes(Sensitivity,Specificity))+geom_point() + xlim(0,1) + ylim(0,1) + ggtitle("Naive Bayes")

plot4 <- ggplot(conf_RF_df, aes(Sensitivity,Specificity))+geom_point() + xlim(0,1) + ylim(0,1) + ggtitle("Random Forest")

grid.arrange(plot3, plot4, nrow=2, ncol=1)
```

It is clear there are more points towards the top right quadrant in the random forest, which implies a high sensitivity and specificity. 


```{r, echo=F, include=F}
detach("package:tm", unload=TRUE)
```

## Association Rule Mining with Groceries
```{r, echo=F, include=F}
library(arules) 
groc <-read.transactions("groceries.txt", format="basket", sep=",")
groc <- groc[!duplicated(groc)]
```

The data contains rows with baskets of goods purchased by each customer. First, lets generate association rules with the apriori principle and inspect it. The support was set at 0.01, which means a combination of goods would have to be purchased 1% of overall baskets to be included in our analysis. The confidence is set at 0.6, and maximum length is 4, since I felt 60% is a reasonable confidence level for meaningful interpretation, and large baskets will not impact the analysis by much.

```{r, echo=F}
grocery <- apriori(groc, parameter=list(support=.01, confidence=.6, maxlen=4))
```

269 rules have been generated. Lets subset the results of the rules in a few ways:

```{r, echo=F}
inspect(subset(grocery, subset=lift > 3))
inspect(subset(grocery, subset=confidence > 0.7))
inspect(subset(grocery, subset=support > .01 & confidence > 0.6))

```
We see that a lot of rules end up modeling combinations of items in baskets that also include dairy items such as yogurt and milk or different types of vegetables. We can see that people who buy vegetables and fruits in general tend to purchase root vegetables, and people who buy certain combinations of yogurt and fruit are likely to purchase whole milk.
