}
# Need a more clever regex to get better names here
train_all_docs = lapply(file_list, readerPlain)
names(train_all_docs) = file_list
names(train_all_docs) = sub('.txt', '', names(train_all_docs))
train_my_corpus = Corpus(VectorSource(train_all_docs))
names(train_my_corpus) = train_file_list
# Preprocessing
train_my_corpus = tm_map(train_my_corpus, content_transformer(tolower)) # make everything lowercase
train_my_corpus = tm_map(train_my_corpus, content_transformer(removeNumbers)) # remove numbers
train_my_corpus = tm_map(train_my_corpus, content_transformer(removePunctuation)) # remove punctuation
train_my_corpus = tm_map(train_my_corpus, content_transformer(stripWhitespace)) ## remove excess white-space
train_my_corpus = tm_map(train_my_corpus, content_transformer(removeWords), stopwords("SMART"))
train_DTM = DocumentTermMatrix(train_my_corpus)
train_DTM # some basic summary statistics
class(train_DTM)  # a special kind of sparse matrix format
train_DTM = removeSparseTerms(train_DTM, 0.975)
train_DTM
train_author_dirs = Sys.glob('ReutersC50/C50train/*')
train_file_list = NULL
train_labels = NULL
for(author in train_author_dirs) {
author_name = substring(author, first=29)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(train_file_list, files_to_add)
labels = append(labels, rep(author_name, length(files_to_add)))
}
# Need a more clever regex to get better names here
train_all_docs = lapply(file_list, readerPlain)
names(train_all_docs) = file_list
names(train_all_docs) = sub('.txt', '', names(train_all_docs))
train_my_corpus = Corpus(VectorSource(train_all_docs))
names(train_my_corpus) = train_file_list
# Preprocessing
train_my_corpus = tm_map(train_my_corpus, content_transformer(tolower)) # make everything lowercase
train_my_corpus = tm_map(train_my_corpus, content_transformer(removeNumbers)) # remove numbers
train_my_corpus = tm_map(train_my_corpus, content_transformer(removePunctuation)) # remove punctuation
train_my_corpus = tm_map(train_my_corpus, content_transformer(stripWhitespace)) ## remove excess white-space
train_my_corpus = tm_map(train_my_corpus, content_transformer(removeWords), stopwords("SMART"))
train_DTM = DocumentTermMatrix(train_my_corpus)
train_DTM # some basic summary statistics
## You can inspect its entries...
train_DTM = removeSparseTerms(train_DTM, 0.975)
train_DTM
## You can inspect its entries...
train_DTM = removeSparseTerms(train_DTM, 0.975)
train_DTM
test_author_dirs = Sys.glob('ReutersC50/C50test/*')
test_file_list = NULL
test_labels = NULL
for(author in test_author_dirs) {
author_name = substring(author, first=29)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(file_list, files_to_add)
labels = append(labels, rep(author_name, length(test_files_to_add)))
}
test_author_dirs = Sys.glob('ReutersC50/C50test/*')
test_file_list = NULL
test_labels = NULL
for(author in test_author_dirs) {
author_name = substring(author, first=29)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(file_list, files_to_add)
labels = append(labels, rep(author_name, length(files_to_add)))
}
test_all_docs = lapply(test_file_list, readerPlain)
names(test_all_docs) = test_file_list
names(test_all_docs) = sub('.txt', '', names(test_all_docs))
test_my_corpus = Corpus(VectorSource(test_all_docs))
names(test_my_corpus) = file_list
names(test_my_corpus) = test_file_list
test_my_corpus = tm_map(test_my_corpus, content_transformer(tolower)) # make everything lowercase
test_my_corpus = tm_map(test_my_corpus, content_transformer(removeNumbers)) # remove numbers
test_my_corpus = tm_map(test_my_corpus, content_transformer(removePunctuation)) # remove punctuation
test_my_corpus = tm_map(test_my_corpus, content_transformer(stripWhitespace)) ## remove excess white-space
test_my_corpus = tm_map(test_my_corpus, content_transformer(removeWords), stopwords("SMART"))
test_DTM = DocumentTermMatrix(test_my_corpus)
test_DTM # some basic summary statistics
test_author_dirs = Sys.glob('ReutersC50/C50test/*')
test_file_list = NULL
test_labels = NULL
for(author in test_author_dirs) {
author_name = substring(author, first=29)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(file_list, files_to_add)
labels = append(labels, rep(author_name, length(files_to_add)))
}
# Need a more clever regex to get better names here
test_all_docs = lapply(test_file_list, readerPlain)
names(test_all_docs) = test_file_list
test_my_corpus = Corpus(VectorSource(test_all_docs))
names(test_all_docs) = sub('.txt', '', names(test_all_docs))
names(test_my_corpus) = test_file_list
# Preprocessing
test_my_corpus = tm_map(test_my_corpus, content_transformer(tolower)) # make everything lowercase
test_my_corpus = tm_map(test_my_corpus, content_transformer(removeNumbers)) # remove numbers
test_my_corpus = tm_map(test_my_corpus, content_transformer(removePunctuation)) # remove punctuation
test_my_corpus = tm_map(test_my_corpus, content_transformer(stripWhitespace)) ## remove excess white-space
test_my_corpus = tm_map(test_my_corpus, content_transformer(removeWords), stopwords("SMART"))
test_DTM = DocumentTermMatrix(test_my_corpus)
test_DTM # some basic summary statistics
test_author_dirs = Sys.glob('ReutersC50/C50test/*')
test_file_list = NULL
test_labels = NULL
for(author in test_author_dirs) {
author_name = substring(author, first=29)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(test_file_list, files_to_add)
labels = append(labels, rep(author_name, length(files_to_add)))
}
# Need a more clever regex to get better names here
test_all_docs = lapply(test_file_list, readerPlain)
names(test_all_docs) = test_file_list
names(test_all_docs) = sub('.txt', '', names(test_all_docs))
test_my_corpus = Corpus(VectorSource(test_all_docs))
names(test_my_corpus) = test_file_list
# Preprocessing
test_my_corpus = tm_map(test_my_corpus, content_transformer(tolower)) # make everything lowercase
test_my_corpus = tm_map(test_my_corpus, content_transformer(removeNumbers)) # remove numbers
test_my_corpus = tm_map(test_my_corpus, content_transformer(removePunctuation)) # remove punctuation
test_my_corpus = tm_map(test_my_corpus, content_transformer(stripWhitespace)) ## remove excess white-space
test_my_corpus = tm_map(test_my_corpus, content_transformer(removeWords), stopwords("SMART"))
test_DTM = DocumentTermMatrix(test_my_corpus)
test_DTM # some basic summary statistics
test_author_dirs = Sys.glob('ReutersC50/C50test/*')
test_file_list = NULL
test_labels = NULL
for(author in test_author_dirs) {
author_name = substring(author, first=29)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(test_file_list, files_to_add)
labels = append(labels, rep(author_name, length(files_to_add)))
}
# Need a more clever regex to get better names here
test_all_docs = lapply(file_list, readerPlain)
names(test_all_docs) = file_list
names(test_all_docs) = sub('.txt', '', names(test_all_docs))
test_my_corpus = Corpus(VectorSource(test_all_docs))
names(test_my_corpus) = test_file_list
# Preprocessing
test_my_corpus = tm_map(test_my_corpus, content_transformer(tolower)) # make everything lowercase
test_my_corpus = tm_map(test_my_corpus, content_transformer(removeNumbers)) # remove numbers
test_my_corpus = tm_map(test_my_corpus, content_transformer(removePunctuation)) # remove punctuation
test_my_corpus = tm_map(test_my_corpus, content_transformer(stripWhitespace)) ## remove excess white-space
test_my_corpus = tm_map(test_my_corpus, content_transformer(removeWords), stopwords("SMART"))
test_DTM = DocumentTermMatrix(test_my_corpus)
test_DTM # some basic summary statistics
test_DTM = removeSparseTerms(train_DTM, 0.975)
test_DTM
train_DTM = removeSparseTerms(train_DTM, 0.975)
train_DTM
DTM_train_df <- as.data.frame(inspect(train_DTM))
require(e1071)
DTM_train_df <- as.data.frame(inspect(train_DTM))
library(randomForest)
library(e1071)
library(caret)
library(e1071)
library(randomForest)
DTM_train_df <- as.data.frame(inspect(train_DTM))
library(tm)
?inspect
library(arules)
DTM_train_df <- as.data.frame(inspect(train_DTM))
list(dictionary=reuters_dict)
reuters_dict = NULL
list(dictionary=reuters_dict)
DTM_test = DocumentTermMatrix(test_corpus, list(dictionary=reuters_dict))
DTM_test_df = as.data.frame(inspect(DTM_test))
DTM_test = DocumentTermMatrix(test_corpus, list(dictionary=reuters_dict))
DTM_test = DocumentTermMatrix(test_my_corpus, list(dictionary=reuters_dict))
DTM_test_df = as.data.frame(inspect(DTM_test))
detach(arules)
detach("package:arules", unload=TRUE)
library(tm)
DTM_test = DocumentTermMatrix(test_my_corpus, list(dictionary=reuters_dict))
DTM_test_df = as.data.frame(inspect(DTM_test))
?inspect
DTM_train_df <- as.data.frame(inspect(train_DTM))
model_NB = naiveBayes(x=DTM_train_df, y=as.factor(train_labels), laplace=1)
DTM_test_df = as.data.frame(inspect(test_DTM))
DTM_train_df <- as.data.frame(inspect(train_DTM))
model_NB = naiveBayes(x=DTM_train_df, y=as.factor(train_labels), laplace=1)
DTM_test = DocumentTermMatrix(test_my_corpus, list(dictionary=reuters_dict))
DTM_test_df = as.data.frame(inspect(test_DTM))
DTM_train_df <- as.data.frame(inspect(train_DTM))
model_NB = naiveBayes(x=DTM_train_df, y=as.factor(train_labels), laplace=1)
DTM_test = DocumentTermMatrix(test_my_corpus, list(dictionary=reuters_dict))
DTM_test = removeSparseTerms(DTM_test, 0.975)
DTM_test_df = as.data.frame(inspect(DTM_test))
DTM_train_df <- as.data.frame(inspect(train_DTM))
model_NB = naiveBayes(x=DTM_train_df, y=as.factor(train_labels), laplace=1)
DTM_train_df = as.data.frame(inspect(train_DTM))
DTM_test_df = as.data.frame(inspect(DTM_test))
model_NB = naiveBayes(x=DTM_train_df, y=as.factor(train_labels), laplace=1)
library(tm)
train_author_dirs = Sys.glob('ReutersC50/C50train/*')
train_file_list = NULL
train_labels = NULL
for(author in train_author_dirs) {
author_name = substring(author, first=29)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(train_file_list, files_to_add)
train_labels = append(train_labels, rep(author_name, length(files_to_add)))
}
# Need a more clever regex to get better names here
train_all_docs = lapply(file_list, readerPlain)
names(train_all_docs) = file_list
names(train_all_docs) = sub('.txt', '', names(train_all_docs))
train_my_corpus = Corpus(VectorSource(train_all_docs))
names(train_my_corpus) = train_file_list
# Preprocessing
train_my_corpus = tm_map(train_my_corpus, content_transformer(tolower)) # make everything lowercase
train_my_corpus = tm_map(train_my_corpus, content_transformer(removeNumbers)) # remove numbers
train_my_corpus = tm_map(train_my_corpus, content_transformer(removePunctuation)) # remove punctuation
train_my_corpus = tm_map(train_my_corpus, content_transformer(stripWhitespace)) ## remove excess white-space
train_my_corpus = tm_map(train_my_corpus, content_transformer(removeWords), stopwords("SMART"))
train_DTM = DocumentTermMatrix(train_my_corpus)
train_DTM = removeSparseTerms(train_DTM, 0.975)
train_DTM
test_author_dirs = Sys.glob('ReutersC50/C50test/*')
test_file_list = NULL
test_labels = NULL
for(author in test_author_dirs) {
author_name = substring(author, first=29)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(test_file_list, files_to_add)
labels = append(labels, rep(author_name, length(files_to_add)))
}
# Need a more clever regex to get better names here
test_all_docs = lapply(file_list, readerPlain)
names(test_all_docs) = file_list
names(test_all_docs) = sub('.txt', '', names(test_all_docs))
test_my_corpus = Corpus(VectorSource(test_all_docs))
names(test_my_corpus) = test_file_list
# Preprocessing
test_my_corpus = tm_map(test_my_corpus, content_transformer(tolower)) # make everything lowercase
test_my_corpus = tm_map(test_my_corpus, content_transformer(removeNumbers)) # remove numbers
test_my_corpus = tm_map(test_my_corpus, content_transformer(removePunctuation)) # remove punctuation
test_my_corpus = tm_map(test_my_corpus, content_transformer(stripWhitespace)) ## remove excess white-space
test_my_corpus = tm_map(test_my_corpus, content_transformer(removeWords), stopwords("SMART"))
test_DTM = DocumentTermMatrix(test_my_corpus)
test_DTM = removeSparseTerms(train_DTM, 0.975)
test_DTM
reuters_dict = NULL
list(dictionary=reuters_dict)
DTM_test = DocumentTermMatrix(test_my_corpus, list(dictionary=reuters_dict))
DTM_test = removeSparseTerms(DTM_test, 0.975)
DTM_train_df = as.data.frame(inspect(train_DTM))
DTM_test_df = as.data.frame(inspect(DTM_test))
model_NB = naiveBayes(x=DTM_train_df, y=as.factor(train_labels), laplace=1)
test_author_dirs = Sys.glob('ReutersC50/C50test/*')
test_file_list = NULL
test_labels = NULL
for(author in test_author_dirs) {
author_name = substring(author, first=29)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(test_file_list, files_to_add)
test_labels = append(test_labels, rep(author_name, length(files_to_add)))
}
# Need a more clever regex to get better names here
test_all_docs = lapply(file_list, readerPlain)
names(test_all_docs) = file_list
names(test_all_docs) = sub('.txt', '', names(test_all_docs))
test_my_corpus = Corpus(VectorSource(test_all_docs))
names(test_my_corpus) = test_file_list
# Preprocessing
test_my_corpus = tm_map(test_my_corpus, content_transformer(tolower)) # make everything lowercase
test_my_corpus = tm_map(test_my_corpus, content_transformer(removeNumbers)) # remove numbers
test_my_corpus = tm_map(test_my_corpus, content_transformer(removePunctuation)) # remove punctuation
test_my_corpus = tm_map(test_my_corpus, content_transformer(stripWhitespace)) ## remove excess white-space
test_my_corpus = tm_map(test_my_corpus, content_transformer(removeWords), stopwords("SMART"))
test_DTM = DocumentTermMatrix(test_my_corpus)
test_DTM = removeSparseTerms(train_DTM, 0.975)
test_DTM
reuters_dict = NULL
list(dictionary=reuters_dict)
DTM_test = DocumentTermMatrix(test_my_corpus, list(dictionary=reuters_dict))
DTM_test = removeSparseTerms(DTM_test, 0.975)
DTM_train_df = as.data.frame(inspect(train_DTM))
DTM_test_df = as.data.frame(inspect(DTM_test))
model_NB = naiveBayes(x=DTM_train_df, y=as.factor(train_labels), laplace=1)
model_NB = naiveBayes(x=DTM_train_df, y=as.factor(train_labels), laplace=1)
library(tm)
readerPlain = function(fname){
readPlain(elem=list(content=readLines(fname)),
id=fname, language='en') }
train_author_dirs = Sys.glob('ReutersC50/C50train/*')
train_file_list = NULL
train_labels = NULL
for(author in train_author_dirs) {
author_name = substring(author, first=29)
file_list = append(train_file_list, files_to_add)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
train_labels = append(train_labels, rep(author_name, length(files_to_add)))
}
# Need a more clever regex to get better names here
train_all_docs = lapply(file_list, readerPlain)
names(train_all_docs) = file_list
names(train_all_docs) = sub('.txt', '', names(train_all_docs))
train_my_corpus = Corpus(VectorSource(train_all_docs))
names(train_my_corpus) = train_file_list
# Preprocessing
train_my_corpus = tm_map(train_my_corpus, content_transformer(tolower)) # make everything lowercase
train_my_corpus = tm_map(train_my_corpus, content_transformer(removeNumbers)) # remove numbers
train_my_corpus = tm_map(train_my_corpus, content_transformer(removePunctuation)) # remove punctuation
train_my_corpus = tm_map(train_my_corpus, content_transformer(stripWhitespace)) ## remove excess white-space
train_my_corpus = tm_map(train_my_corpus, content_transformer(removeWords), stopwords("SMART"))
train_DTM = DocumentTermMatrix(train_my_corpus)
train_DTM
train_DTM = removeSparseTerms(train_DTM, 0.975)
test_author_dirs = Sys.glob('ReutersC50/C50test/*')
test_file_list = NULL
test_labels = NULL
for(author in test_author_dirs) {
author_name = substring(author, first=29)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(test_file_list, files_to_add)
test_labels = append(test_labels, rep(author_name, length(files_to_add)))
}
# Need a more clever regex to get better names here
test_all_docs = lapply(file_list, readerPlain)
names(test_all_docs) = file_list
names(test_all_docs) = sub('.txt', '', names(test_all_docs))
test_my_corpus = Corpus(VectorSource(test_all_docs))
names(test_my_corpus) = test_file_list
# Preprocessing
test_my_corpus = tm_map(test_my_corpus, content_transformer(tolower)) # make everything lowercase
test_my_corpus = tm_map(test_my_corpus, content_transformer(removeNumbers)) # remove numbers
test_my_corpus = tm_map(test_my_corpus, content_transformer(removePunctuation)) # remove punctuation
test_my_corpus = tm_map(test_my_corpus, content_transformer(removeWords), stopwords("SMART"))
test_my_corpus = tm_map(test_my_corpus, content_transformer(stripWhitespace)) ## remove excess white-space
test_DTM = DocumentTermMatrix(test_my_corpus)
test_DTM = removeSparseTerms(train_DTM, 0.975)
test_DTM
reuters_dict = NULL
list(dictionary=reuters_dict)
DTM_test = DocumentTermMatrix(test_my_corpus, list(dictionary=reuters_dict))
DTM_test = removeSparseTerms(DTM_test, 0.975)
DTM_train_df = as.data.frame(inspect(train_DTM))
DTM_test_df = as.data.frame(inspect(DTM_test))
model_NB = naiveBayes(x=DTM_train_df, y=as.factor(train_labels), laplace=1)
reuters_dict = NULL
list(dictionary=reuters_dict)
DTM_test = DocumentTermMatrix(test_my_corpus, list(dictionary=reuters_dict))
test_DTM = DocumentTermMatrix(test_my_corpus)
test_DTM = removeSparseTerms(test_DTM, 0.975)
test_DTM
DTM_train_df = as.data.frame(inspect(train_DTM))
DTM_test_df = as.data.frame(inspect(DTM_test))
model_NB = naiveBayes(x=DTM_train_df, y=as.factor(train_labels), laplace=1)
library(tm)
library(randomForest)
library(e1071)
library(rpart)
library(ggplot2)
library(caret)
#reader function
readerPlain = function(fname){
readPlain(elem=list(content=readLines(fname)), id=fname, language='en') }
#################
#TRAINING CORPUS#
#################
author_dirs = Sys.glob('ReutersC50/C50train/*')
file_list = NULL
train_labels = NULL
for(author in author_dirs) {
author_name = substring(author, first=23)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(file_list, files_to_add)
train_labels = append(train_labels, rep(author_name, length(files_to_add)))
}
# Named conversion & cleanup
all_docs = lapply(file_list, readerPlain)
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))
#Initialize Training Corpus
train_corpus = Corpus(VectorSource(all_docs))
names(train_corpus) = file_list
#Tokenization of training Corpus
train_corpus = tm_map(train_corpus, content_transformer(tolower))
train_corpus = tm_map(train_corpus, content_transformer(removeNumbers))
train_corpus = tm_map(train_corpus, content_transformer(removePunctuation))
train_corpus = tm_map(train_corpus, content_transformer(stripWhitespace))
train_corpus = tm_map(train_corpus, content_transformer(removeWords), stopwords("SMART"))
#Create training DTM & dense matrix
DTM_train = DocumentTermMatrix(train_corpus)
DTM_train = removeSparseTerms(DTM_train, 0.975)
#DTM_train = as.matrix(DTM_train)
DTM_train
################
#TESTING CORPUS#
################
author_dirs = Sys.glob('ReutersC50/C50test/*')
file_list = NULL
test_labels = NULL
for(author in author_dirs) {
author_name = substring(author, first=22)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(file_list, files_to_add)
test_labels = append(test_labels, rep(author_name, length(files_to_add)))
}
# Named conversion & cleanup
all_docs = lapply(file_list, readerPlain)
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))
#Initialize Testing Corpus
test_corpus = Corpus(VectorSource(all_docs))
names(test_corpus) = file_list
#Tokenization of Testing Corpus
test_corpus = tm_map(test_corpus, content_transformer(tolower))
test_corpus = tm_map(test_corpus, content_transformer(removeNumbers))
test_corpus = tm_map(test_corpus, content_transformer(removePunctuation))
test_corpus = tm_map(test_corpus, content_transformer(stripWhitespace))
test_corpus = tm_map(test_corpus, content_transformer(removeWords), stopwords("SMART"))
#### Dictionary Creation ####
# We need a dictionary of terms from the training corpus
# in order to extract terms from the test corpus
reuters_dict = NULL
reuters_dict = dimnames(DTM_train)[[2]]
#Create testing DTM & matrix using dictionary words only
DTM_test = DocumentTermMatrix(test_corpus, list(dictionary=reuters_dict))
DTM_test = removeSparseTerms(DTM_test, 0.975)
#DTM_test = as.matrix(DTM_test)
## Convert DTMs into Data Frames for use in classifier models
DTM_train_df = as.data.frame(inspect(DTM_train))
#DTM_train$auth_name = train_labels
DTM_test_df = as.data.frame(inspect(DTM_test))
#DTM_test$auth_name = test_labels
######### Naive Bayes Model #########
model_NB = naiveBayes(x=DTM_train_df, y=as.factor(train_labels), laplace=1)
pred_NB = predict(model_NB, DTM_test_df)
table_NB = as.data.frame(table(pred_NB,test_labels))
plot = ggplot(table_NB)
plot + geom_tile(aes(x=test_labels, y=pred_NB, fill=Freq)) +
scale_x_discrete(name="Actual Class") +
scale_y_discrete(name="Predicted Class") +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
table_NB
tableplot(table_NB)
library(ggplot2)
tableplot(table_NB)
install.packages("tabplot")
require(tabplot)
tableplot(table_NB)
conf_NB = confusionMatrix(table(pred_NB,test_labels))
conf_NB_df = as.data.frame(conf_NB$byClass)
conf_NB_df[order(-conf_NB_df$Sensitivity),1:2]
tableplot(conf_NB_df)
conf_NB_df_1 = conf_NB$byClass[1]
tableplot(conf_NB_df_1)
conf_NB_df_1 = conf_NB$byClass[,1]
tableplot(conf_NB_df_1)
conf_NB_df_1 = conf_NB[1]
tableplot(conf_NB_df_1)
conf_NB_df_1 = conf_NB_df$Sensitivity
tableplot(conf_NB_df_1)
cnbd1<-conf_NB_df[order(-conf_NB_df$Sensitivity),1]
tableplot(cnbd1)
cnbd1<-conf_NB_df#[order(-conf_NB_df$Sensitivity),1]
tableplot(cnbd1)
tableplot(conf_NB_df$Sensitivity)
tableplot(conf_NB_df)
conf_NB = confusionMatrix(table(pred_NB,test_labels))
conf_NB_df = as.data.frame(conf_NB$byClass)
conf_NB_df[order(-conf_NB_df$Sensitivity),1:2]
tableplot(conf_NB_df)
conf_NB = confusionMatrix(table(pred_NB,test_labels))
conf_NB_df = as.data.frame(conf_NB$byClass)
conf_NB_df[order(-conf_NB_df$Sensitivity),1:2]
tableplot(conf_NB_df)
table_NB = as.data.frame(table(pred_NB,test_labels))
conf_NB = confusionMatrix(table(pred_NB,test_labels))
conf_NB_df = as.data.frame(conf_NB$byClass)
conf_NB_df[order(-conf_NB_df$Sensitivity),1:2]
tableplot(conf_NB_df)
tableplot(conf_NB_df)
tableplot(conf_NB_df)
tableplot(conf_NB_df)
DTM_test = as.matrix(DTM_test)
DTM_train = as.matrix(DTM_train)
xx <- data.frame(DTM_test[,intersect(colnames(DTM_test), colnames(DTM_train))])
yy <- read.table(textConnection(""), col.names = colnames(DTM_train), colClasses = "integer")
library(plyr)
DTM_test_clean = rbind.fill(xx, yy)
DTM_test_df = as.data.frame(DTM_test_clean)
model_RF = randomForest(x=DTM_train_df, y=as.factor(train_labels), mtry=3, ntree=200)
pred_RF = predict(model_RF, data=DTM_test_clean)
table_RF = as.data.frame(table(pred_RF,test_labels))
tableplot(conf_NB_dfbyClass)
tableplot(conf_NB_df$byClass)
tableplot(conf_NB_df$byClass, conf_NB_df$Sensitivity)
tableplot(conf_NB_df)
conf_NB_df
qplot(conf_NB_df$Class,conf_NB_df$Sensitivity)
ggplot(conf_NB_df, aes(Class,Sensitivity))+geom_point()
ggplot(conf_NB_df, aes(Sensitivity,Specificity))+geom_point()
plot + geom_tile(aes(x=test_labels, y=pred_RF, fill=Freq)) +
scale_x_discrete(name="Actual Class") +
scale_y_discrete(name="Predicted Class") +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(table_RF, aes(test_labels,pred_RF))+geom_point()
conf_RF = confusionMatrix(table(pred_RF,test_labels))
conf_RF$overall
conf_RF_df[order(-conf_RF_df$Sensitivity),1:2]
conf_RF_df = as.data.frame(conf_RF$byClass)
ggplot(conf_RF, aes(Sensitivity,specificity()))+geom_point()
conf_RF_df = as.data.frame(conf_RF$byClass)
ggplot(conf_RF_df, aes(Sensitivity,specificity()))+geom_point()
ggplot(conf_RF_df, aes(Sensitivity,Specificity()))+geom_point()
conf_RF_df
ggplot(conf_RF_df, aes(Sensitivity,Specificity))+geom_point()
